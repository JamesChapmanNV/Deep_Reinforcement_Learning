{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning: Deep Q-Networks, Double DQN, & Dueling DQN\n",
    "<br>\n",
    "James Chapman<br>\n",
    "CIS 730 Artificial Intelligence â€“ Term Project<br>\n",
    "Kansas State University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Hyperparameters & Control](#Hyperparameters&Control)<br>\n",
    "[Gymnasium Wrappers](#GymnasiumWrappers)<br>\n",
    "[Convolutional Neural Network](#ConvolutionalNeuralNetwork)<br>\n",
    "[Agent](#Agent)<br>\n",
    "[Initialization](#Initialization)<br>\n",
    "[Testing](#Testing)<br>\n",
    "[Save](#Save)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install \"gymnasium[atari, accept-rom-license]\"\n",
    "    !pip install stable_baselines3\n",
    "    !pip install ale-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd gdrive/My Drive/Atari\n",
    "    \n",
    "    from psutil import virtual_memory\n",
    "    ram_gb = virtual_memory().total / 1e9\n",
    "    print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "    if ram_gb < 20:\n",
    "        print('Not using a high-RAM runtime')\n",
    "    else:\n",
    "        print('You are using a high-RAM runtime!')\n",
    "\n",
    "    gpu_info = !nvidia-smi\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "        print('Not connected to a GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "\n",
    "import gymnasium as gym\n",
    "#from gymnasium.wrappers import FrameStack,GrayScaleObservation,ResizeObservation\n",
    "from stable_baselines3.common.atari_wrappers import FireResetEnv,MaxAndSkipEnv,NoopResetEnv#EpisodicLifeEnv,ClipRewardEnv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2\n",
    "import collections \n",
    "from collections import deque\n",
    "from typing import Dict, List, Tuple\n",
    "from IPython import display\n",
    "plt.ion()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Control some randomness, for reproducibility\n",
    "torch.manual_seed(0) \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.manual_seed_all(0)   \n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Hyperparameters&Control'></a>\n",
    "## Hyperparameters & Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGwHC9dyXoPd"
   },
   "outputs": [],
   "source": [
    "ENV_NAME = \"PongNoFrameskip-v4\" \n",
    "# ENV_NAME = \"BreakoutNoFrameskip-v4\"\n",
    "# ENV_NAME = \"SpaceInvadersNoFrameskip-v4\" \n",
    "# ENV_NAME = \"MsPacmanNoFrameskip-v4\"\n",
    "# ENV_NAME = \"QbertNoFrameskip-v4\"\n",
    "# ENV_NAME = \"LunarLander-v2\" \n",
    "\n",
    "NETWORK_SAVE_PATH = 'models/Pong-DOUBLE'\n",
    "DATA_SAVE_PATH = 'data/Pong-DOUBLE'\n",
    "                                            \n",
    "is_dueling = False\n",
    "noop_max = 30\n",
    "\n",
    "num_frames = 3e6\n",
    "warmup_size = 10000\n",
    "\n",
    "test_interval = 250000\n",
    "test_num_frames = 50000\n",
    "\n",
    "test_epsilon = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRcuJGVSQi6g"
   },
   "source": [
    "<a id='GymnasiumWrappers'></a>\n",
    "## Gymnasium Wrappers \n",
    "#### Same as Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 210 * 160 * 3:\n",
    "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
    "        elif frame.size == 250 * 160 * 3:\n",
    "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[18:102, :]\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "    ############################\n",
    "    # CONVERTED to Gymnasium\n",
    "    # def reset(self):\n",
    "    #    self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "    #    return self.observation(self.env.reset())\n",
    "    def reset(self, **kwargs):# CONVERTED to Gymnasium\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        return self.observation(obs), info\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], \n",
    "                                old_shape[0], old_shape[1]), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PongWrappers(env):\n",
    "    print('Creating environment------------')\n",
    "    env = MaxAndSkipEnv(env, 4) # From stable_baselines3\n",
    "    env = FireResetEnv(env)  # From stable_baselines3\n",
    "    env = NoopResetEnv(env, noop_max=noop_max)  # From stable_baselines3\n",
    "    \n",
    "    print(env.observation_space)\n",
    "    env = ProcessFrame84(env)\n",
    "    print(env.observation_space)\n",
    "    env = ImageToPyTorch(env)\n",
    "    print(env.observation_space)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    print(env.observation_space)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    print(env.observation_space)     \n",
    "    print('--------------------------------')\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRcuJGVSQi6g"
   },
   "source": [
    "<a id='ConvolutionalNeuralNetwork'></a>\n",
    "## Convolutional Neural Network\n",
    "#### Same as Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4S1I9xWMkf3"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions, is_dueling):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.n_actions = n_actions\n",
    "        self.is_dueling = is_dueling\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "        self.dueling_value = nn.Sequential(\n",
    "            nn.Linear(self.conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if is_dueling:\n",
    "            ############## Dueling Networks ################\n",
    "            conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "            advantage_out = self.fc(conv_out)\n",
    "            value_out = self.dueling_value(conv_out)\n",
    "            return value_out + advantage_out - advantage_out.mean()\n",
    "            ################################################\n",
    "        else:\n",
    "            conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "            return self.fc(conv_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQDV04ktY3xs"
   },
   "source": [
    "<a id='Agent'></a>\n",
    "## Agent\n",
    "#### Without Experience Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdAKFiMWZw90"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        self.state, info = env.reset() #New\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def play_step(self, net, epsilon, device):\n",
    "        done_reward = None\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            state_a = np.array([self.state], copy=False)\n",
    "            state_v = torch.tensor(state_a).to(device)\n",
    "            q_vals_v = net(state_v)\n",
    "            _, act_v = torch.max(q_vals_v, dim=1)\n",
    "            action = int(act_v.item())\n",
    "            \n",
    "        new_state, reward, terminated, truncated, info = self.env.step(action) #New # clipped_reward = np.clip(reward, -1, 1)\n",
    "        is_done = terminated or truncated  #New\n",
    "        self.total_reward += reward #np.clip(reward, -1, 1)?np.sign(float(reward))\n",
    "            \n",
    "        self.state = new_state\n",
    "        if is_done:\n",
    "            done_reward = self.total_reward\n",
    "            self._reset()\n",
    "        return done_reward\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Initialization'></a>\n",
    "## Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating environment------------\n",
      "Box(0, 255, (210, 160, 3), uint8)\n",
      "Box(0, 255, (84, 84, 1), uint8)\n",
      "Box(0.0, 1.0, (1, 84, 84), float32)\n",
      "Box(0.0, 1.0, (4, 84, 84), float32)\n",
      "Box(0.0, 1.0, (4, 84, 84), float32)\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_env = gym.make(ENV_NAME)\n",
    "env = PongWrappers(base_env)\n",
    "net = ConvNet(env.observation_space.shape, env.action_space.n,is_dueling).to(device)\n",
    "agent = Agent(env)\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "test_results_dict = {}\n",
    "cur_test_interval = 1250000\n",
    "test_results_summary = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Testing'></a>\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_interval(net, interval_SAVE_NAME):\n",
    "    net.load_state_dict(torch.load(interval_SAVE_NAME))\n",
    "    net.eval()\n",
    "    \n",
    "    interval_frame_idxs = []\n",
    "    interval_rewards = []\n",
    "    with torch.inference_mode():\n",
    "        for frame_idx in range(test_num_frames):\n",
    "            reward = agent.play_step(net, test_epsilon, device=device)\n",
    "            if reward is not None:\n",
    "                interval_frame_idxs.append(frame_idx)\n",
    "                interval_rewards.append(reward)\n",
    "                                         \n",
    "    return [interval_frame_idxs, interval_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEoc2PWmM2mu",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250000 15.5 4.74\n",
      "1500000 20.2 1.66\n",
      "1750000 20.38 0.85\n",
      "2000000 20.71 0.68\n",
      "2250000 18.47 8.67\n",
      "2500000 20.47 0.85\n",
      "2750000 20.83 0.45\n",
      "3000000 19.83 0.46\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    \n",
    "    interval_SAVE_NAME = NETWORK_SAVE_PATH + '-{}.dat'.format(cur_test_interval)\n",
    "    interval_test_results = test_model_interval(net, interval_SAVE_NAME)\n",
    "    \n",
    "    test_results_dict[cur_test_interval] = interval_test_results\n",
    "\n",
    "    test_results_summary.append([cur_test_interval,\n",
    "                                 round(np.mean(interval_test_results[1]),2),\n",
    "                                 round(np.std(interval_test_results[1]),2)])\n",
    "    print(cur_test_interval,\n",
    "          round(np.mean(interval_test_results[1]),2),\n",
    "          round(np.std(interval_test_results[1]),2))\n",
    "    \n",
    "    cur_test_interval+= test_interval\n",
    "    if cur_test_interval> num_frames:\n",
    "        break   \n",
    "        \n",
    "# frame_num, score, standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1250000, 15.5, 4.74], [1500000, 20.2, 1.66], [1750000, 20.38, 0.85], [2000000, 20.71, 0.68], [2250000, 18.47, 8.67], [2500000, 20.47, 0.85], [2750000, 20.83, 0.45], [3000000, 19.83, 0.46]]\n"
     ]
    }
   ],
   "source": [
    "print(test_results_summary) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Save'></a>\n",
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Pong-DOUBLE_test_results_dict.npy\n",
      "data/Pong-DOUBLE_test_results_summary.npy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_results_dict_file = DATA_SAVE_PATH + '_test_results_dict.npy'\n",
    "print(test_results_dict_file)\n",
    "with open(test_results_dict_file, 'wb') as f:\n",
    "    np.save(f, test_results_dict)\n",
    "    \n",
    "test_results_summary_file = DATA_SAVE_PATH + '_test_results_summary.npy'\n",
    "print(test_results_summary_file)\n",
    "with open(test_results_summary_file, 'wb') as f:\n",
    "    np.save(f, np.array(test_results_summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2155285666.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    : )\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    ": )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DRL_15_16_17_DQN_Pong.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
